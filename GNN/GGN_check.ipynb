{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка данных"
      ],
      "metadata": {
        "id": "uhqnanpq_30E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 19WJRvdFZgV1hxmVl52HCKq0gieTQk_uY #flats_checks_raster.csv\n",
        "!gdown 1tbxE-SZO5R37TiBscVZ2zbTGeTAIsUYk #таргет price трейн\n",
        "!gdown 1ZI-JsZ-6QxtHJKnxj1Mggscxumodxm64 # таргет price тест"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRnZVhGuRGFS",
        "outputId": "cc59c3b4-007b-49bd-e40c-4f769b03a5ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=19WJRvdFZgV1hxmVl52HCKq0gieTQk_uY\n",
            "From (redirected): https://drive.google.com/uc?id=19WJRvdFZgV1hxmVl52HCKq0gieTQk_uY&confirm=t&uuid=3e0f4049-6dce-4f21-a708-ee473a1bb53b\n",
            "To: /content/flats_checks_raster.csv\n",
            "100% 1.05G/1.05G [00:21<00:00, 48.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tbxE-SZO5R37TiBscVZ2zbTGeTAIsUYk\n",
            "To: /content/y_train_msk_merged_2.pkl\n",
            "100% 788k/788k [00:00<00:00, 4.28MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZI-JsZ-6QxtHJKnxj1Mggscxumodxm64\n",
            "To: /content/y_test_msk_merged_2.pkl\n",
            "100% 140k/140k [00:00<00:00, 7.87MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Предобработка датасетов. Выделение датасетов из единого"
      ],
      "metadata": {
        "id": "fVB65o_l_6c0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# 1. Загружаем и ставим индекс. Это требуется потому, что индексы слетели из-за сокращения датасета после добавления данных ФНС\n",
        "df_mega_base = pd.read_csv('flats_checks_raster.csv', index_col='Unnamed: 0')\n",
        "\n",
        "# 1.1. Загружаем y_train и y_test. Таргеты были отдельно\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "# 2. Объединяем их в один DataFrame\n",
        "y_full = pd.concat([y_train, y_test])\n",
        "\n",
        "# 3. Присоединяем таргеты к df_mega_base по индексу\n",
        "df_mega_base = df_mega_base.join(y_full, how='left')\n",
        "df_mega_base = df_mega_base.reset_index(drop=True)\n",
        "\n",
        "# 2. Удаляем все столбцы с 'emb' в названии. Удаляем эмбеддинги Славы, т.к. датасет содержал эмбеддинги tabfpn, мне они не трубуются\n",
        "df_mega_base = df_mega_base.loc[:, ~df_mega_base.columns.str.contains('emb')]\n",
        "\n",
        "# 3. Удаляем столбцы\n",
        "df_mega_base = df_mega_base.drop([\n",
        "    'TruncatedAverageBill', 'MedianBill',\n",
        "    'lat', 'lng', 'geometry', 'index_right',\n",
        "    'coordinates', 'polygon'\n",
        "], axis=1, errors='ignore')"
      ],
      "metadata": {
        "id": "ab4-tq1-MrFX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# заполняем пропуски средним\n",
        "for column in df_mega_base.columns:\n",
        "    df_mega_base[column].fillna(df_mega_base[column].mean(), inplace=True)\n",
        "\n",
        "# 4. Создаём df_check из столбцов ФНС. на нем будем валидироваться\n",
        "df_check = df_mega_base[[\n",
        "    'KktCount',\n",
        "    'AverageBill',\n",
        "    'CachePayPercent',\n",
        "    'IntensityOfNumberBills',\n",
        "    'RevenueIntensity',\n",
        "    'ReceiptTotalCount',\n",
        "    'price'\n",
        "]].copy()\n",
        "\n",
        "# 5. df_flats_rasters — это оставшиеся столбцы. Получаем датасет только из квартир + POI + растры\n",
        "df_flats_rasters = df_mega_base.drop(columns=df_check.columns, errors='ignore')\n",
        "\n",
        "\n",
        "# 6. Удаляем все столбцы, содержащие 'rast' в названии\n",
        "df_flats = df_flats_rasters.loc[:, ~df_flats_rasters.columns.str.contains('rast')]\n",
        "\n",
        "# 7. Делаем датасет, в котором есть только исходные данные по квартирам (ЦИАН)\n",
        "POI = [\n",
        "    'distance_to_center',\n",
        "    'highways_count',\n",
        "    'undergrounds_count',\n",
        "    'railways_count',\n",
        "    'time_to_metro',\n",
        "    'pop_dense',\n",
        "    'pop_work_dense',\n",
        "    'pop_child_dense',\n",
        "    'avg_age',\n",
        "    'trade_per_pers',\n",
        "    'pers_per_bed',\n",
        "    'self_goods_sold',\n",
        "    'other_goods_sold',\n",
        "    'org_num',\n",
        "    'entrep_num',\n",
        "    'buildings_apartments',\n",
        "    'buildings_service',\n",
        "    'buildings_retail',\n",
        "    'buildings_kindergarten',\n",
        "    'buildings_school',\n",
        "    'buildings_office',\n",
        "    'buildings_construction',\n",
        "    'buildings_commercial',\n",
        "    'buildings_hospital',\n",
        "    'buildings_university',\n",
        "    'buildings_public',\n",
        "    'buildings_industrial',\n",
        "    'buildings_church',\n",
        "    'education',\n",
        "    'food_buy',\n",
        "    'food_out',\n",
        "    'health',\n",
        "    'leisure',\n",
        "    'religion',\n",
        "    'services',\n",
        "    'shopping',\n",
        "    'transport',\n",
        "    'mun_district',\n",
        "]\n",
        "\n",
        "df_flats_without_POI = df_flats.drop(columns=POI, errors='ignore')\n",
        "df_flats_rasters_only = df_flats_rasters.drop(columns=POI, errors='ignore')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIfrAm7MoclU",
        "outputId": "4e66fae2-7f7c-4a1f-970d-714739e30916"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-535601612.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_mega_base[column].fillna(df_mega_base[column].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GNN предсказание на датасете квартир + растровой гео-информации"
      ],
      "metadata": {
        "id": "-xxRMvfkQ6GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install catboost\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from torch_geometric.nn import SAGEConv, BatchNorm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWgPHIFiRKEj",
        "outputId": "38b7b45e-2e4e-45b7-93b5-53c44a0153dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.6.15)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GNN\n",
        "Датасет квартиры МСК"
      ],
      "metadata": {
        "id": "X5owgBClCG6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1. Загрузка и подготовка данных ===\n",
        "y = df_mega_base['price']\n",
        "X = df_flats_without_POI.copy()\n",
        "\n",
        "# Делим на train и test\n",
        "df_train_flats, df_test_flats, y_train_price, y_test_price = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=999\n",
        ")\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train_price.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test_price.values.reshape(-1, 1))\n",
        "\n",
        "# Объединение\n",
        "df_all = pd.concat([df_train_flats, df_test_flats], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# === 2. Построение графа и PyG Data ===\n",
        "A = kneighbors_graph(X_all, n_neighbors=8, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)"
      ],
      "metadata": {
        "id": "YLhhQDtiCIao"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === NEW: определим устройство ===\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Маски\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train_flats)] = True\n",
        "test_mask[len(df_train_flats):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# Переносим data на GPU\n",
        "data = data.to(device)\n",
        "\n",
        "# === 3. GNN модель ===\n",
        "class DeepGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.3):\n",
        "        super(DeepGNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        return self.mlp(x)\n",
        "\n",
        "    def get_embeddings(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "# Инициализация модели и оптимизатора\n",
        "model = DeepGNN(\n",
        "    in_channels=X_all.shape[1],\n",
        "    hidden_channels=128,\n",
        "    out_channels=1\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_fn = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "6paL67GKCIgI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 5. Оценка модели (RMSE на тесте) ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze()\n",
        "    preds_test_scaled = preds_scaled[data.test_mask].cpu().numpy()\n",
        "    y_test_scaled_true = data.y[data.test_mask].squeeze().cpu().numpy()\n",
        "\n",
        "    # Обратное масштабирование\n",
        "    preds_test = target_scaler.inverse_transform(preds_test_scaled.reshape(-1, 1))\n",
        "    y_test_true = target_scaler.inverse_transform(y_test_scaled_true.reshape(-1, 1))\n",
        "\n",
        "    # Вычисляем RMSE\n",
        "    rmse = mean_squared_error(y_test_true, preds_test) ** 0.5\n",
        "    print(f'\\nTest RMSE: {rmse:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "hxQlK7EWCQMI",
        "outputId": "07bcecb9-729b-42ef-871b-b567d7d93204"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 48.4949\n",
            "Epoch 10, Loss: 17.3288\n",
            "Epoch 20, Loss: 10.1148\n",
            "Epoch 30, Loss: 6.6460\n",
            "Epoch 40, Loss: 4.6447\n",
            "Epoch 50, Loss: 3.6701\n",
            "Epoch 60, Loss: 2.9539\n",
            "Epoch 70, Loss: 2.5227\n",
            "Epoch 80, Loss: 2.1545\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-3244138898.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-6-2048267927.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/sage_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_4w26nav_.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, size)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# End Aggregate Forward Pre Hook #######################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         out = self.aggregate(\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mas\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maggr\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \"\"\"\n\u001b[0;32m--> 594\u001b[0;31m         return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,\n\u001b[0m\u001b[1;32m    595\u001b[0m                                 dim=self.node_dim)\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/experimental.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_experimental_mode_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'disable_dynamic_shapes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrequired_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequired_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/aggr/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             return super().__call__(x, index=index, ptr=ptr, dim_size=dim_size,\n\u001b[0m\u001b[1;32m    132\u001b[0m                                     dim=dim, **kwargs)\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/aggr/basic.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mptr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 dim: int = -2) -> Tensor:\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/aggr/base.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Aggregation requires 'index' to be specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     def to_dense_batch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/_scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GNN\n",
        "Датасет квартиры МСК + POI"
      ],
      "metadata": {
        "id": "dOStEq6WCCpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1. Загрузка и подготовка данных ===\n",
        "y = df_mega_base['price']\n",
        "X = df_flats.copy()\n",
        "\n",
        "# Делим на train и test\n",
        "df_train_flats, df_test_flats, y_train_price, y_test_price = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=999\n",
        ")\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train_price.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test_price.values.reshape(-1, 1))\n",
        "\n",
        "# Объединение\n",
        "df_all = pd.concat([df_train_flats, df_test_flats], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# === 2. Построение графа и PyG Data ===\n",
        "A = kneighbors_graph(X_all, n_neighbors=8, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)"
      ],
      "metadata": {
        "id": "CRdICM2IBqqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === NEW: определим устройство ===\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Маски\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train_flats)] = True\n",
        "test_mask[len(df_train_flats):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# Переносим data на GPU\n",
        "data = data.to(device)\n",
        "\n",
        "# === 3. GNN модель ===\n",
        "class DeepGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.3):\n",
        "        super(DeepGNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        return self.mlp(x)\n",
        "\n",
        "    def get_embeddings(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "# Инициализация модели и оптимизатора\n",
        "model = DeepGNN(\n",
        "    in_channels=X_all.shape[1],\n",
        "    hidden_channels=128,\n",
        "    out_channels=1\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_fn = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "UBxf4yM0Bqm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 5. Оценка модели (RMSE на тесте) ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze()\n",
        "    preds_test_scaled = preds_scaled[data.test_mask].cpu().numpy()\n",
        "    y_test_scaled_true = data.y[data.test_mask].squeeze().cpu().numpy()\n",
        "\n",
        "    # Обратное масштабирование\n",
        "    preds_test = target_scaler.inverse_transform(preds_test_scaled.reshape(-1, 1))\n",
        "    y_test_true = target_scaler.inverse_transform(y_test_scaled_true.reshape(-1, 1))\n",
        "\n",
        "    # Вычисляем RMSE\n",
        "    rmse = mean_squared_error(y_test_true, preds_test) ** 0.5\n",
        "    print(f'\\nTest RMSE: {rmse:.2f}')"
      ],
      "metadata": {
        "id": "1amWCsO4Bqcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GNN\n",
        "Датасет квартиры МСК + растровые данные"
      ],
      "metadata": {
        "id": "_3fjVoGgPoNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1. Загрузка и подготовка данных ===\n",
        "y = df_mega_base['price']\n",
        "X = df_flats_rasters\n",
        "\n",
        "# Делим на train и test\n",
        "df_train_flats, df_test_flats, y_train_price, y_test_price = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=999\n",
        ")\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train_price.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test_price.values.reshape(-1, 1))\n",
        "\n",
        "# Объединение\n",
        "df_all = pd.concat([df_train_flats, df_test_flats], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# === 2. Построение графа и PyG Data ===\n",
        "A = kneighbors_graph(X_all, n_neighbors=8, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)"
      ],
      "metadata": {
        "id": "-nljJGskPh0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === NEW: определим устройство ===\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Маски\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train_flats)] = True\n",
        "test_mask[len(df_train_flats):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# Переносим data на GPU\n",
        "data = data.to(device)\n",
        "\n",
        "# === 3. GNN модель ===\n",
        "class DeepGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.3):\n",
        "        super(DeepGNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        return self.mlp(x)\n",
        "\n",
        "    def get_embeddings(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "# Инициализация модели и оптимизатора\n",
        "model = DeepGNN(\n",
        "    in_channels=X_all.shape[1],\n",
        "    hidden_channels=128,\n",
        "    out_channels=1\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_fn = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "bBEVeBOTPhxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 5. Оценка модели (RMSE на тесте) ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze()\n",
        "    preds_test_scaled = preds_scaled[data.test_mask].cpu().numpy()\n",
        "    y_test_scaled_true = data.y[data.test_mask].squeeze().cpu().numpy()\n",
        "\n",
        "    # Обратное масштабирование\n",
        "    preds_test = target_scaler.inverse_transform(preds_test_scaled.reshape(-1, 1))\n",
        "    y_test_true = target_scaler.inverse_transform(y_test_scaled_true.reshape(-1, 1))\n",
        "\n",
        "    # Вычисляем RMSE\n",
        "    rmse = mean_squared_error(y_test_true, preds_test) ** 0.5\n",
        "    print(f'\\nTest RMSE: {rmse:.2f}')"
      ],
      "metadata": {
        "id": "SVSQiFvRPhuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GNN\n",
        "Датасет квартиры МСК + POI + растровые данные"
      ],
      "metadata": {
        "id": "POtCYJKdDMRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1. Загрузка и подготовка данных ===\n",
        "y = df_mega_base['price']\n",
        "X = df_flats_rasters.copy()\n",
        "\n",
        "# Делим на train и test\n",
        "df_train_flats, df_test_flats, y_train_price, y_test_price = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=999\n",
        ")\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train_price.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test_price.values.reshape(-1, 1))\n",
        "\n",
        "# Объединение\n",
        "df_all = pd.concat([df_train_flats, df_test_flats], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# === 2. Построение графа и PyG Data ===\n",
        "A = kneighbors_graph(X_all, n_neighbors=8, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)"
      ],
      "metadata": {
        "id": "7xRqtCT1z8u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === NEW: определим устройство ===\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Маски\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train_flats)] = True\n",
        "test_mask[len(df_train_flats):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# Переносим data на GPU\n",
        "data = data.to(device)\n",
        "\n",
        "# === 3. GNN модель ===\n",
        "class DeepGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.3):\n",
        "        super(DeepGNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        return self.mlp(x)\n",
        "\n",
        "    def get_embeddings(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "# Инициализация модели и оптимизатора\n",
        "model = DeepGNN(\n",
        "    in_channels=X_all.shape[1],\n",
        "    hidden_channels=128,\n",
        "    out_channels=1\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "ovvO1re81BGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 5. Оценка модели (RMSE на тесте) ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze()\n",
        "    preds_test_scaled = preds_scaled[data.test_mask].cpu().numpy()\n",
        "    y_test_scaled_true = data.y[data.test_mask].squeeze().cpu().numpy()\n",
        "\n",
        "    # Обратное масштабирование\n",
        "    preds_test = target_scaler.inverse_transform(preds_test_scaled.reshape(-1, 1))\n",
        "    y_test_true = target_scaler.inverse_transform(y_test_scaled_true.reshape(-1, 1))\n",
        "\n",
        "    # Вычисляем RMSE\n",
        "    rmse = mean_squared_error(y_test_true, preds_test) ** 0.5\n",
        "    print(f'\\nTest RMSE: {rmse:.2f}')"
      ],
      "metadata": {
        "id": "Uv7z9l8p1FBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это лучший результат, извлечем его эмбеддинги для дальнейшего использования"
      ],
      "metadata": {
        "id": "lX5C5eYIHL1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 5. Извлечение эмбеддингов ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    embeddings = model.get_embeddings(data.x, data.edge_index).cpu().numpy()"
      ],
      "metadata": {
        "id": "JjjXr2vIRCzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Создаем DataFrame с эмбеддингами и правильными индексами из X_all\n",
        "embeddings = pd.DataFrame(embeddings, index=df_mega_base.index)\n",
        "embeddings.to_csv('embeddings.csv')"
      ],
      "metadata": {
        "id": "fNElScMxHWxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#подгружаем эмбеддинги, чтобы не пересчитывать\n",
        "!gdown 1pZIcstb6kL90U8NfTpDKd7TOHr2FtEFC\n",
        "embeddings = pd.read_csv('embeddings.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CPmu5JP_RAi",
        "outputId": "a82b690c-a8c0-446e-80e6-1ac522a6c354"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pZIcstb6kL90U8NfTpDKd7TOHr2FtEFC\n",
            "To: /content/embeddings.csv\n",
            "100% 46.3M/46.3M [00:00<00:00, 90.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Валидация. Датасет с фискальными данными"
      ],
      "metadata": {
        "id": "VbKh4ATrG99I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Предсказание catboost на сыром датасете"
      ],
      "metadata": {
        "id": "iKNtWJk98A6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# === 1. Берем df_check и определяем X и y ===\n",
        "target_col = 'AverageBill'\n",
        "X = df_check.drop(columns=[target_col])\n",
        "y = df_check[target_col]\n",
        "\n",
        "# === 2. Делим на train/test ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=999\n",
        ")\n",
        "\n",
        "# === 3. Масштабируем признаки по train ===\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# === 4. Обучение CatBoost ===\n",
        "model = CatBoostRegressor(\n",
        "    iterations=500,\n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    verbose=0,\n",
        "    random_state=999\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === 5. Предсказания и оценка RMSE ===\n",
        "y_pred = model.predict(X_test)\n",
        "rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "print(f'RMSE: {rmse:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyEabaL96YXo",
        "outputId": "447d28c5-9734-4f36-857d-3d77e1a51293"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 120.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Предсказание catboost на датасете с добавленными эмбеддингами из GNN"
      ],
      "metadata": {
        "id": "UE8onZWa7_dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Создаем DataFrame с эмбеддингами и правильными индексами из X_all\n",
        "emb_df = pd.DataFrame(embeddings, index=df_mega_base.index)\n",
        "emb_df.columns = [f'emb_{i}' for i in range(embeddings.shape[1])]\n",
        "\n",
        "# 2. Присоединяем эмбеддинги по индексу\n",
        "existing_cols = set(df_check.columns)\n",
        "\n",
        "# 3. Отбираем только те столбцы из emb_df, которых нет в df_check\n",
        "emb_to_add = emb_df[[col for col in emb_df.columns if col not in existing_cols]]\n",
        "\n",
        "# 4. Присоединяем по индексу\n",
        "df_check_emb = df_check.join(emb_to_add, how='left')"
      ],
      "metadata": {
        "id": "M6TC_QCnDSFx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# === 1. Берем df_check и определяем X и y ===\n",
        "target_col = 'AverageBill'\n",
        "X = df_check_emb.drop(columns=[target_col])\n",
        "y = df_check_emb[target_col]\n",
        "\n",
        "# === 2. Делим на train/test ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=999\n",
        ")\n",
        "\n",
        "# === 3. Масштабируем признаки по train ===\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# === 4. Обучение CatBoost ===\n",
        "model = CatBoostRegressor(\n",
        "    iterations=500,\n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    verbose=0,\n",
        "    random_state=999\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === 5. Предсказания и оценка RMSE ===\n",
        "y_pred = model.predict(X_test)\n",
        "rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "print(f'RMSE: {rmse:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE5hWc9R4YKh",
        "outputId": "e299f923-0e1f-4ba7-8211-2829f4ac4ece"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 130.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На датасете с фискальной информацией полученные GNN на квартирах эмбеддинги не дали улучшения метрики, а наоборот - ухудшили результаты. Видимо, они внесли шум, либо датасет квартир был недостаточно большим"
      ],
      "metadata": {
        "id": "u3whnLYs_4D5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nMD7qVZvAW9g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}