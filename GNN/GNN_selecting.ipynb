{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqlczZ8j4iMk",
        "outputId": "2e7964ea-3142-48b1-fb3a-b3a7f242b743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1q4UCHs2JvZZltJ1QzKydWogMBNUQhftm\n",
            "To: /content/X_train_mosc_wembs.pickle\n",
            "100% 34.1M/34.1M [00:00<00:00, 96.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=188hwfGDnLjFCQsQiJXKBSAm1cOJeprtF\n",
            "To: /content/X_test_mosc_wembs.pickle\n",
            "100% 6.03M/6.03M [00:00<00:00, 60.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tbxE-SZO5R37TiBscVZ2zbTGeTAIsUYk\n",
            "To: /content/y_train_msk_merged_2.pkl\n",
            "100% 788k/788k [00:00<00:00, 47.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZI-JsZ-6QxtHJKnxj1Mggscxumodxm64\n",
            "To: /content/y_test_msk_merged_2.pkl\n",
            "100% 140k/140k [00:00<00:00, 38.1MB/s]\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.6.15)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!gdown 1q4UCHs2JvZZltJ1QzKydWogMBNUQhftm\n",
        "!gdown 188hwfGDnLjFCQsQiJXKBSAm1cOJeprtF\n",
        "!gdown 1tbxE-SZO5R37TiBscVZ2zbTGeTAIsUYk\n",
        "!gdown 1ZI-JsZ-6QxtHJKnxj1Mggscxumodxm64\n",
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lyT79tC4rY7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlGgrJusdu6L",
        "outputId": "5825bed1-335e-4642-f509-51732f2eb0db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-53-1782627843.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
            "/tmp/ipython-input-53-1782627843.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 5.3641\n",
            "Epoch 20, Loss: 0.3516\n",
            "Epoch 40, Loss: 0.2118\n",
            "Epoch 60, Loss: 0.1910\n",
            "Epoch 80, Loss: 0.1839\n",
            "Epoch 100, Loss: 0.1798\n",
            "Epoch 120, Loss: 0.1764\n",
            "Epoch 140, Loss: 0.1734\n",
            "Epoch 160, Loss: 0.1708\n",
            "Epoch 180, Loss: 0.1683\n",
            "Epoch 200, Loss: 0.1660\n",
            "Epoch 220, Loss: 0.1640\n",
            "Epoch 240, Loss: 0.1621\n",
            "Epoch 260, Loss: 0.1610\n",
            "Epoch 280, Loss: 0.1590\n",
            "Epoch 300, Loss: 0.1583\n",
            "Epoch 320, Loss: 0.1553\n",
            "Epoch 340, Loss: 0.1582\n",
            "Epoch 360, Loss: 0.1530\n",
            "Epoch 380, Loss: 0.1527\n",
            "Epoch 400, Loss: 0.1519\n",
            "Epoch 420, Loss: 0.1529\n",
            "Epoch 440, Loss: 0.1512\n",
            "Epoch 460, Loss: 0.1510\n",
            "Epoch 480, Loss: 0.1489\n",
            "True values: [19750000. 10100000. 16900000. 31900000. 31300000. 29000000. 13150000.\n",
            " 37000000.  9771580. 14900000.]\n",
            "Predictions: [19321666. 10567110. 11671585. 31074312. 32347326. 24625944. 16482421.\n",
            " 33327422. 10402218. 15796223.]\n",
            "Test RMSE: 7617069.39\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "# Загрузка\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем для построения общего графа\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "\n",
        "# Извлекаем только признаки\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# Строим граф по KNN (10 ближайших соседей)\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# Создаём PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Разбиваем обратно на train/test\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 2. Определение модели ===\n",
        "\n",
        "class SimpleGCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(SimpleGCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "model = SimpleGCN(in_channels=X_all.shape[1], hidden_channels=64, out_channels=1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# === 3. Обучение модели ===\n",
        "\n",
        "model.train()\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 4. Оценка ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze().cpu().numpy()\n",
        "    preds = target_scaler.inverse_transform(preds_scaled.reshape(-1, 1)).flatten()\n",
        "    true = y_train.tolist() + y_test.tolist()\n",
        "\n",
        "    # Выводим первые 10\n",
        "    print('True values:', np.array(true[:10]))\n",
        "    print('Predictions:', preds[:10])\n",
        "\n",
        "    # RMSE по тесту\n",
        "    rmse = mean_squared_error(\n",
        "        y_test,\n",
        "        preds[len(df_train):]\n",
        "    ) ** 0.5\n",
        "    print(f'Test RMSE: {rmse:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUFLGKhgyu5f"
      },
      "source": [
        "# Simple GNN 500 epochs LR=0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAq13NnXdu3x",
        "outputId": "1b57a2e7-b722-4acc-f839-de10e1465008"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-54-2536647009.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
            "/tmp/ipython-input-54-2536647009.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 0.9369\n",
            "Epoch 20, Loss: 0.2764\n",
            "Epoch 40, Loss: 0.2209\n",
            "Epoch 60, Loss: 0.2038\n",
            "Epoch 80, Loss: 0.1945\n",
            "Epoch 100, Loss: 0.1883\n",
            "Epoch 120, Loss: 0.1834\n",
            "Epoch 140, Loss: 0.1797\n",
            "Epoch 160, Loss: 0.1764\n",
            "Epoch 180, Loss: 0.1734\n",
            "Epoch 200, Loss: 0.1705\n",
            "Epoch 220, Loss: 0.1680\n",
            "Epoch 240, Loss: 0.1659\n",
            "Epoch 260, Loss: 0.1642\n",
            "Epoch 280, Loss: 0.1626\n",
            "Epoch 300, Loss: 0.1611\n",
            "Epoch 320, Loss: 0.1598\n",
            "Epoch 340, Loss: 0.1586\n",
            "Epoch 360, Loss: 0.1574\n",
            "Epoch 380, Loss: 0.1563\n",
            "Epoch 400, Loss: 0.1552\n",
            "Epoch 420, Loss: 0.1543\n",
            "Epoch 440, Loss: 0.1534\n",
            "Epoch 460, Loss: 0.1525\n",
            "Epoch 480, Loss: 0.1517\n",
            "True values: [19750000. 10100000. 16900000. 31900000. 31300000. 29000000. 13150000.\n",
            " 37000000.  9771580. 14900000.]\n",
            "Predictions: [20517988. 10573108. 10621115. 29240722. 32322828. 26622184. 16462741.\n",
            " 34351924. 10978047. 15486948.]\n",
            "Test RMSE: 7548791.52\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "# Загрузка\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем для построения общего графа\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "\n",
        "# Извлекаем только признаки\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# Строим граф по KNN (10 ближайших соседей)\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# Создаём PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Разбиваем обратно на train/test\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 2. Определение модели ===\n",
        "\n",
        "class SimpleGCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(SimpleGCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "model = SimpleGCN(in_channels=X_all.shape[1], hidden_channels=64, out_channels=1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# === 3. Обучение модели ===\n",
        "\n",
        "model.train()\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 4. Оценка ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze().cpu().numpy()\n",
        "    preds = target_scaler.inverse_transform(preds_scaled.reshape(-1, 1)).flatten()\n",
        "    true = y_train.tolist() + y_test.tolist()\n",
        "\n",
        "    # Выводим первые 10\n",
        "    print('True values:', np.array(true[:10]))\n",
        "    print('Predictions:', preds[:10])\n",
        "\n",
        "    # RMSE по тесту\n",
        "    rmse = mean_squared_error(\n",
        "        y_test,\n",
        "        preds[len(df_train):]\n",
        "    ) ** 0.5\n",
        "    print(f'Test RMSE: {rmse:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6C52JLtym0Z"
      },
      "source": [
        "# GNN advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-GP9_wywihA"
      },
      "source": [
        "Несколько GNN-слоёв (GCN, GraphSAGE или GAT).\n",
        "\n",
        "Нормализацию (BatchNorm).\n",
        "\n",
        "Dropout.\n",
        "\n",
        "Residual connection.\n",
        "\n",
        "MLP в конце.\n",
        "\n",
        "Меняем архитектуру модели: комбинация GraphSAGE + BatchNorm + Dropout + MLP:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbA5YkP0yQ4F"
      },
      "source": [
        "## 500 EPOCHS LR=0.001 DROPOUT=0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXKv9QdxvF-i",
        "outputId": "3eeded0d-24ac-477e-aad6-5bd7d6471014"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-58-1825460662.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
            "/tmp/ipython-input-58-1825460662.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 0.9985\n",
            "Epoch 20, Loss: 0.2003\n",
            "Epoch 40, Loss: 0.1539\n",
            "Epoch 60, Loss: 0.1385\n",
            "Epoch 80, Loss: 0.1274\n",
            "Epoch 100, Loss: 0.1175\n",
            "Epoch 120, Loss: 0.1101\n",
            "Epoch 140, Loss: 0.1072\n",
            "Epoch 160, Loss: 0.1022\n",
            "Epoch 180, Loss: 0.0992\n",
            "Epoch 200, Loss: 0.0964\n",
            "Epoch 220, Loss: 0.0920\n",
            "Epoch 240, Loss: 0.0902\n",
            "Epoch 260, Loss: 0.0912\n",
            "Epoch 280, Loss: 0.0881\n",
            "Epoch 300, Loss: 0.0850\n",
            "Epoch 320, Loss: 0.0834\n",
            "Epoch 340, Loss: 0.0828\n",
            "Epoch 360, Loss: 0.0802\n",
            "Epoch 380, Loss: 0.0788\n",
            "Epoch 400, Loss: 0.0786\n",
            "Epoch 420, Loss: 0.0742\n",
            "Epoch 440, Loss: 0.0742\n",
            "Epoch 460, Loss: 0.0738\n",
            "Epoch 480, Loss: 0.0731\n",
            "True values: [19750000. 10100000. 16900000. 31900000. 31300000. 29000000. 13150000.\n",
            " 37000000.  9771580. 14900000.]\n",
            "Predictions: [17263888. 10534946. 14193814. 30599792. 29395228. 25365090. 13391490.\n",
            " 52319568. 10345269. 13846885.]\n",
            "Test RMSE: 5082855.62\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from torch_geometric.nn import SAGEConv, BatchNorm\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "# Загрузка\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем для построения общего графа\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "\n",
        "# Извлекаем только признаки\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# Строим граф по KNN (10 ближайших соседей)\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# Создаём PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Разбиваем обратно на train/test\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 2. Определение модели ===\n",
        "\n",
        "class DeepGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.3):\n",
        "        super(DeepGNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.mlp(x)\n",
        "        return x\n",
        "\n",
        "model = DeepGNN(in_channels=X_all.shape[1], hidden_channels=128, out_channels=1, dropout=0.4)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# === 3. Обучение модели ===\n",
        "\n",
        "model.train()\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 4. Оценка ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze().cpu().numpy()\n",
        "    preds = target_scaler.inverse_transform(preds_scaled.reshape(-1, 1)).flatten()\n",
        "    true = y_train.tolist() + y_test.tolist()\n",
        "\n",
        "    # Выводим первые 10\n",
        "    print('True values:', np.array(true[:10]))\n",
        "    print('Predictions:', preds[:10])\n",
        "\n",
        "    # RMSE по тесту\n",
        "    rmse = mean_squared_error(\n",
        "        y_test,\n",
        "        preds[len(df_train):]\n",
        "    ) ** 0.5\n",
        "    print(f'Test RMSE: {rmse:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWVbZ8yEN2L5"
      },
      "source": [
        "## 700 EPOCHS LR=0.001 DROPOUT=0.4 ** BEST **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXtzBnmRFUfT",
        "outputId": "7f832a0d-fb1b-43f4-ba48-109739ba840c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-5-818942232.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
            "/tmp/ipython-input-5-818942232.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 1.0327\n",
            "Epoch 20, Loss: 0.2144\n",
            "Epoch 40, Loss: 0.1694\n",
            "Epoch 60, Loss: 0.1452\n",
            "Epoch 80, Loss: 0.1297\n",
            "Epoch 100, Loss: 0.1210\n",
            "Epoch 120, Loss: 0.1137\n",
            "Epoch 140, Loss: 0.1097\n",
            "Epoch 160, Loss: 0.1048\n",
            "Epoch 180, Loss: 0.1028\n",
            "Epoch 200, Loss: 0.1003\n",
            "Epoch 220, Loss: 0.0978\n",
            "Epoch 240, Loss: 0.0930\n",
            "Epoch 260, Loss: 0.0925\n",
            "Epoch 280, Loss: 0.0896\n",
            "Epoch 300, Loss: 0.0859\n",
            "Epoch 320, Loss: 0.0857\n",
            "Epoch 340, Loss: 0.0826\n",
            "Epoch 360, Loss: 0.0805\n",
            "Epoch 380, Loss: 0.0799\n",
            "Epoch 400, Loss: 0.0797\n",
            "Epoch 420, Loss: 0.0758\n",
            "Epoch 440, Loss: 0.0756\n",
            "Epoch 460, Loss: 0.0747\n",
            "Epoch 480, Loss: 0.0753\n",
            "Epoch 500, Loss: 0.0723\n",
            "Epoch 520, Loss: 0.0721\n",
            "Epoch 540, Loss: 0.0705\n",
            "Epoch 560, Loss: 0.0703\n",
            "Epoch 580, Loss: 0.0681\n",
            "Epoch 600, Loss: 0.0676\n",
            "Epoch 620, Loss: 0.0666\n",
            "Epoch 640, Loss: 0.0656\n",
            "Epoch 660, Loss: 0.0654\n",
            "Epoch 680, Loss: 0.0661\n",
            "True values: [19750000. 10100000. 16900000. 31900000. 31300000. 29000000. 13150000.\n",
            " 37000000.  9771580. 14900000.]\n",
            "Predictions: [16983026. 10677627. 14862286. 31084332. 27892986. 28782262. 14036999.\n",
            " 48253224. 10221474. 13263708.]\n",
            "Test RMSE: 5214217.88\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from torch_geometric.nn import SAGEConv, BatchNorm\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "# Загрузка\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем для построения общего графа\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "\n",
        "# Извлекаем только признаки\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# Строим граф по KNN (10 ближайших соседей)\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# Создаём PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Разбиваем обратно на train/test\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 2. Определение модели ===\n",
        "\n",
        "class DeepGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.3):\n",
        "        super(DeepGNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.mlp(x)\n",
        "        return x\n",
        "\n",
        "model = DeepGNN(in_channels=X_all.shape[1], hidden_channels=128, out_channels=1, dropout=0.4)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# === 3. Обучение модели ===\n",
        "\n",
        "model.train()\n",
        "for epoch in range(700):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 4. Оценка ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze().cpu().numpy()\n",
        "    preds = target_scaler.inverse_transform(preds_scaled.reshape(-1, 1)).flatten()\n",
        "    true = y_train.tolist() + y_test.tolist()\n",
        "\n",
        "    # Выводим первые 10\n",
        "    print('True values:', np.array(true[:10]))\n",
        "    print('Predictions:', preds[:10])\n",
        "\n",
        "    # RMSE по тесту\n",
        "    rmse = mean_squared_error(\n",
        "        y_test,\n",
        "        preds[len(df_train):]\n",
        "    ) ** 0.5\n",
        "    print(f'Test RMSE: {rmse:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKjhWZcd-6ze"
      },
      "source": [
        "# папам\n",
        "\n",
        "Построение графа на объединённых данных\n",
        "✅ 2\tТренировка DeepGNN\n",
        "✅ 3\tИзвлечение эмбеддингов\n",
        "✅ 4\tCatBoost на исходных признаках\n",
        "✅ 5\tCatBoost на признаки + GNN-эмбеддинги"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYCDvZVg_EbA",
        "outputId": "3710e5d9-9d55-4618-878d-5b4d99531f62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "j8WLwdUiNxiB",
        "outputId": "351bf6cd-dcfe-4ea7-9448-f1f12a45df93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-12-4241561232.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[col].fillna(df_train[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-12-4241561232.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[col].fillna(df_test[col].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 1.0554\n",
            "Epoch 50, Loss: 0.1504\n",
            "Epoch 100, Loss: 0.1204\n",
            "Epoch 150, Loss: 0.1030\n",
            "Epoch 200, Loss: 0.0958\n",
            "Epoch 250, Loss: 0.0914\n",
            "Epoch 300, Loss: 0.0861\n",
            "Epoch 350, Loss: 0.0826\n",
            "Epoch 400, Loss: 0.0779\n",
            "Epoch 450, Loss: 0.0785\n",
            "\n",
            "=== CatBoost RMSE по различным признаковым пространствам ===\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "got an unexpected keyword argument 'squared'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-12-4241561232.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n=== CatBoost RMSE по различным признаковым пространствам ==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m \u001b[0mpred1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate_catboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1. Исходные признаки'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0mpred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate_catboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2. Только GNN-эмбеддинги'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m pred3 = train_and_evaluate_catboost(\n",
            "\u001b[0;32m/tmp/ipython-input-12-4241561232.py\u001b[0m in \u001b[0;36mtrain_and_evaluate_catboost\u001b[0;34m(X_train, X_test, name)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mpreds_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{name} RMSE: {rmse:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m# Map *args/**kwargs to the function signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mcan\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3194\u001b[0m         \"\"\"\n\u001b[0;32m-> 3195\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbind_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m_bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3182\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3183\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3184\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m   3185\u001b[0m                     'got an unexpected keyword argument {arg!r}'.format(\n\u001b[1;32m   3186\u001b[0m                         arg=next(iter(kwargs))))\n",
            "\u001b[0;31mTypeError\u001b[0m: got an unexpected keyword argument 'squared'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import SAGEConv, BatchNorm\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "# Заполнение пропусков\n",
        "for col in df_train.columns:\n",
        "    df_train[col].fillna(df_train[col].mean(), inplace=True)\n",
        "    df_test[col].fillna(df_test[col].mean(), inplace=True)\n",
        "\n",
        "# Масштабирование таргета\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединение train + test\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# === 2. Построение графа и PyG Data ===\n",
        "\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 3. GNN модель ===\n",
        "\n",
        "class DeepGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.4):\n",
        "        super(DeepGNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = BatchNorm(hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = BatchNorm(hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "        return self.mlp(x)\n",
        "\n",
        "    def get_embeddings(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "model = DeepGNN(in_channels=X_all.shape[1], hidden_channels=128, out_channels=1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# === 4. Обучение GNN ===\n",
        "\n",
        "model.train()\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 50 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 5. Извлечение эмбеддингов ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    embeddings = model.get_embeddings(data.x, data.edge_index).cpu().numpy()\n",
        "emb_train = embeddings[data.train_mask]\n",
        "emb_test = embeddings[data.test_mask]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmPpoPA-NxeG",
        "outputId": "05ffc4a6-8e22-4a6b-b9d3-d4e9edceda87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== CatBoost RMSE по различным признаковым пространствам ===\n",
            "1. Исходные признаки RMSE: 5319891.68\n",
            "2. Только GNN-эмбеддинги RMSE: 5225126.92\n",
            "3. Признаки + GNN-эмбеддинги RMSE: 5201237.01\n",
            "\n",
            "🔍 Примеры предсказаний для CatBoost (вариант 3):\n",
            "True:  [29000000. 60000000. 82000000. 18500000. 14000000. 21900000. 90000000.\n",
            " 21500000. 17950000. 71000000.]\n",
            "Pred:  [27749979.73009477 51173209.27768907 77033958.63143659 18230162.35398448\n",
            " 12455446.44858989 22174369.30963769 95585119.95531502 19483789.04615035\n",
            " 19714213.25770666 79151156.27625135]\n"
          ]
        }
      ],
      "source": [
        "def train_and_evaluate_catboost(X_train, X_test, name):\n",
        "    model = CatBoostRegressor(\n",
        "        iterations=500,\n",
        "        learning_rate=0.05,\n",
        "        depth=6,\n",
        "        loss_function='RMSE',\n",
        "        verbose=0\n",
        "    )\n",
        "    model.fit(X_train, y_train_scaled.ravel())\n",
        "    preds_scaled = model.predict(X_test)\n",
        "    preds = target_scaler.inverse_transform(preds_scaled.reshape(-1, 1)).ravel()\n",
        "    rmse = mean_squared_error(y_test, preds) ** 0.5\n",
        "    print(f'{name} RMSE: {rmse:.2f}')\n",
        "    return preds\n",
        "\n",
        "print('\\n=== CatBoost RMSE по различным признаковым пространствам ===')\n",
        "pred1 = train_and_evaluate_catboost(df_train.values, df_test.values, '1. Исходные признаки')\n",
        "pred2 = train_and_evaluate_catboost(emb_train, emb_test, '2. Только GNN-эмбеддинги')\n",
        "pred3 = train_and_evaluate_catboost(\n",
        "    np.hstack([df_train.values, emb_train]),\n",
        "    np.hstack([df_test.values, emb_test]),\n",
        "    '3. Признаки + GNN-эмбеддинги'\n",
        ")\n",
        "\n",
        "# === 7. Примеры предсказаний ===\n",
        "\n",
        "print('\\n🔍 Примеры предсказаний для CatBoost (вариант 3):')\n",
        "print('True: ', y_test.values[:10].ravel())\n",
        "print('Pred: ', pred3[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQWYJeriHPV_",
        "outputId": "62e11e99-1f08-4089-b4fe-bd80a4e420be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-14-709222157.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
            "/tmp/ipython-input-14-709222157.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 0.9894\n",
            "Epoch 20, Loss: 0.2015\n",
            "Epoch 40, Loss: 0.1593\n",
            "Epoch 60, Loss: 0.1399\n",
            "Epoch 80, Loss: 0.1264\n",
            "Epoch 100, Loss: 0.1173\n",
            "Epoch 120, Loss: 0.1088\n",
            "Epoch 140, Loss: 0.1039\n",
            "Epoch 160, Loss: 0.1009\n",
            "Epoch 180, Loss: 0.0989\n",
            "Epoch 200, Loss: 0.0926\n",
            "Epoch 220, Loss: 0.0903\n",
            "Epoch 240, Loss: 0.0906\n",
            "Epoch 260, Loss: 0.0876\n",
            "Epoch 280, Loss: 0.0861\n",
            "Epoch 300, Loss: 0.0816\n",
            "Epoch 320, Loss: 0.0802\n",
            "Epoch 340, Loss: 0.0817\n",
            "Epoch 360, Loss: 0.0795\n",
            "Epoch 380, Loss: 0.0780\n",
            "CatBoost [A] только признаки RMSE: 5188808.43\n",
            "CatBoost [B] признаки + эмбеддинги RMSE: 5194884.08\n",
            "CatBoost [C] только эмбеддинги RMSE: 5309247.49\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import SAGEConv, BatchNorm\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "# Обработка пропусков\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем признаки и таргеты\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# === 2. Строим граф по KNN (10 соседей) ===\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Маски\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 3. GNN-модель ===\n",
        "class DeepGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.3):\n",
        "        super(DeepGNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = BatchNorm(hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = BatchNorm(hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, return_embeddings=False):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return x  # Вернуть эмбеддинги до MLP\n",
        "        return self.mlp(x)\n",
        "\n",
        "# === 4. Обучение GNN ===\n",
        "\n",
        "model = DeepGNN(in_channels=X_all.shape[1], hidden_channels=128, out_channels=1, dropout=0.4)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(400):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 5. Извлечение эмбеддингов ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    embeddings = model(data.x, data.edge_index, return_embeddings=True).cpu().numpy()\n",
        "    emb_train = embeddings[:len(df_train)]\n",
        "    emb_test = embeddings[len(df_train):]\n",
        "\n",
        "# === 6. Обучение CatBoost на трех вариантах ===\n",
        "\n",
        "X_train_std = df_train.values\n",
        "X_test_std = df_test.values\n",
        "\n",
        "X_train_concat = np.hstack([X_train_std, emb_train])\n",
        "X_test_concat = np.hstack([X_test_std, emb_test])\n",
        "\n",
        "# Опции CatBoost\n",
        "params = dict(verbose=0, iterations=300, random_seed=42)\n",
        "\n",
        "def run_catboost(X_tr, X_te, name=''):\n",
        "    model = CatBoostRegressor(**params)\n",
        "    model.fit(X_tr, y_train)\n",
        "    preds = model.predict(X_te)\n",
        "    rmse = mean_squared_error(y_test, preds) ** 0.5\n",
        "    print(f'CatBoost {name} RMSE: {rmse:.2f}')\n",
        "    return rmse\n",
        "\n",
        "rmse_std = run_catboost(X_train_std, X_test_std, name='[A] только признаки')\n",
        "rmse_concat = run_catboost(X_train_concat, X_test_concat, name='[B] признаки + эмбеддинги')\n",
        "rmse_emb = run_catboost(emb_train, emb_test, name='[C] только эмбеддинги')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbXlZLXrHPTL",
        "outputId": "d5131950-5b91-4ce7-f1ff-58d07300199b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-16-4036878003.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
            "/tmp/ipython-input-16-4036878003.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 1.0057\n",
            "Epoch 20, Loss: 0.5634\n",
            "Epoch 40, Loss: 0.3233\n",
            "Epoch 60, Loss: 0.2522\n",
            "Epoch 80, Loss: 0.2278\n",
            "Epoch 100, Loss: 0.2200\n",
            "Epoch 120, Loss: 0.2050\n",
            "Epoch 140, Loss: 0.1925\n",
            "Epoch 160, Loss: 0.1824\n",
            "Epoch 180, Loss: 0.1794\n",
            "Epoch 200, Loss: 0.1755\n",
            "Epoch 220, Loss: 0.1690\n",
            "Epoch 240, Loss: 0.1627\n",
            "Epoch 260, Loss: 0.1548\n",
            "Epoch 280, Loss: 0.1554\n",
            "Epoch 300, Loss: 0.1499\n",
            "Epoch 320, Loss: 0.1458\n",
            "Epoch 340, Loss: 0.1410\n",
            "Epoch 360, Loss: 0.1394\n",
            "Epoch 380, Loss: 0.1350\n",
            "Epoch 400, Loss: 0.1313\n",
            "Epoch 420, Loss: 0.1318\n",
            "Epoch 440, Loss: 0.1283\n",
            "Epoch 460, Loss: 0.1288\n",
            "Epoch 480, Loss: 0.1263\n",
            "Epoch 500, Loss: 0.1218\n",
            "Epoch 520, Loss: 0.1213\n",
            "Epoch 540, Loss: 0.1221\n",
            "Epoch 560, Loss: 0.1178\n",
            "Epoch 580, Loss: 0.1196\n",
            "Epoch 600, Loss: 0.1167\n",
            "Epoch 620, Loss: 0.1125\n",
            "Epoch 640, Loss: 0.1115\n",
            "Epoch 660, Loss: 0.1099\n",
            "Epoch 680, Loss: 0.1108\n",
            "CatBoost [A] только признаки RMSE: 5188808.43\n",
            "CatBoost [B] признаки + эмбеддинги RMSE: 5147010.55\n",
            "CatBoost [C] только эмбеддинги RMSE: 5459178.06\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import SAGEConv, BatchNorm\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "# Обработка пропусков\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем признаки и таргеты\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# === 2. Строим граф по KNN (10 соседей) ===\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Маски\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 3. GNN-модель ===\n",
        "class DeepGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.3):\n",
        "        super(DeepGNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = BatchNorm(hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = BatchNorm(hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, return_embeddings=False):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return x  # Вернуть эмбеддинги до MLP\n",
        "        return self.mlp(x)\n",
        "\n",
        "# === 4. Обучение GNN ===\n",
        "\n",
        "model = DeepGNN(in_channels=X_all.shape[1], hidden_channels=128, out_channels=1, dropout=0.4)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(700):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 5. Извлечение эмбеддингов ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    embeddings = model(data.x, data.edge_index, return_embeddings=True).cpu().numpy()\n",
        "    emb_train = embeddings[:len(df_train)]\n",
        "    emb_test = embeddings[len(df_train):]\n",
        "\n",
        "# === 6. Обучение CatBoost на трех вариантах ===\n",
        "\n",
        "X_train_std = df_train.values\n",
        "X_test_std = df_test.values\n",
        "\n",
        "X_train_concat = np.hstack([X_train_std, emb_train])\n",
        "X_test_concat = np.hstack([X_test_std, emb_test])\n",
        "\n",
        "# Опции CatBoost\n",
        "params = dict(verbose=0, iterations=300, random_seed=42)\n",
        "\n",
        "def run_catboost(X_tr, X_te, name=''):\n",
        "    model = CatBoostRegressor(**params)\n",
        "    model.fit(X_tr, y_train)\n",
        "    preds = model.predict(X_te)\n",
        "    rmse = mean_squared_error(y_test, preds) ** 0.5\n",
        "    print(f'CatBoost {name} RMSE: {rmse:.2f}')\n",
        "    return rmse\n",
        "\n",
        "rmse_std = run_catboost(X_train_std, X_test_std, name='[A] только признаки')\n",
        "rmse_concat = run_catboost(X_train_concat, X_test_concat, name='[B] признаки + эмбеддинги')\n",
        "rmse_emb = run_catboost(emb_train, emb_test, name='[C] только эмбеддинги')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjtBmUUFHPQa",
        "outputId": "4e436bae-c36a-4085-a5b7-f5be6017f10d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-17-2762226429.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
            "/tmp/ipython-input-17-2762226429.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 0.9787\n",
            "Epoch 20, Loss: 0.5554\n",
            "Epoch 40, Loss: 0.2886\n",
            "Epoch 60, Loss: 0.2349\n",
            "Epoch 80, Loss: 0.2116\n",
            "Epoch 100, Loss: 0.1965\n",
            "Epoch 120, Loss: 0.1813\n",
            "Epoch 140, Loss: 0.1712\n",
            "Epoch 160, Loss: 0.1702\n",
            "Epoch 180, Loss: 0.1613\n",
            "Epoch 200, Loss: 0.1543\n",
            "Epoch 220, Loss: 0.1506\n",
            "Epoch 240, Loss: 0.1449\n",
            "Epoch 260, Loss: 0.1408\n",
            "Epoch 280, Loss: 0.1384\n",
            "Epoch 300, Loss: 0.1318\n",
            "Epoch 320, Loss: 0.1300\n",
            "Epoch 340, Loss: 0.1275\n",
            "Epoch 360, Loss: 0.1227\n",
            "Epoch 380, Loss: 0.1226\n",
            "Epoch 400, Loss: 0.1203\n",
            "Epoch 420, Loss: 0.1174\n",
            "Epoch 440, Loss: 0.1156\n",
            "Epoch 460, Loss: 0.1136\n",
            "Epoch 480, Loss: 0.1133\n",
            "Epoch 500, Loss: 0.1078\n",
            "Epoch 520, Loss: 0.1070\n",
            "Epoch 540, Loss: 0.1050\n",
            "Epoch 560, Loss: 0.1064\n",
            "Epoch 580, Loss: 0.1037\n",
            "Epoch 600, Loss: 0.1009\n",
            "Epoch 620, Loss: 0.1012\n",
            "Epoch 640, Loss: 0.1002\n",
            "Epoch 660, Loss: 0.0996\n",
            "Epoch 680, Loss: 0.0973\n",
            "CatBoost [A] только признаки RMSE: 5188808.43\n",
            "CatBoost [B] признаки + эмбеддинги RMSE: 5134052.80\n",
            "CatBoost [C] только эмбеддинги RMSE: 5428254.37\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import SAGEConv, BatchNorm\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "# Обработка пропусков\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем признаки и таргеты\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# === 2. Строим граф по KNN (10 соседей) ===\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Маски\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 3. GNN-модель ===\n",
        "class DeepGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.3):\n",
        "        super(DeepGNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = BatchNorm(hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = BatchNorm(hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, return_embeddings=False):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return x  # Вернуть эмбеддинги до MLP\n",
        "        return self.mlp(x)\n",
        "\n",
        "# === 4. Обучение GNN ===\n",
        "\n",
        "model = DeepGNN(in_channels=X_all.shape[1], hidden_channels=128, out_channels=1, dropout=0.3)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(700):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 5. Извлечение эмбеддингов ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    embeddings = model(data.x, data.edge_index, return_embeddings=True).cpu().numpy()\n",
        "    emb_train = embeddings[:len(df_train)]\n",
        "    emb_test = embeddings[len(df_train):]\n",
        "\n",
        "# === 6. Обучение CatBoost на трех вариантах ===\n",
        "\n",
        "X_train_std = df_train.values\n",
        "X_test_std = df_test.values\n",
        "\n",
        "X_train_concat = np.hstack([X_train_std, emb_train])\n",
        "X_test_concat = np.hstack([X_test_std, emb_test])\n",
        "\n",
        "# Опции CatBoost\n",
        "params = dict(verbose=0, iterations=300, random_seed=42)\n",
        "\n",
        "def run_catboost(X_tr, X_te, name=''):\n",
        "    model = CatBoostRegressor(**params)\n",
        "    model.fit(X_tr, y_train)\n",
        "    preds = model.predict(X_te)\n",
        "    rmse = mean_squared_error(y_test, preds) ** 0.5\n",
        "    print(f'CatBoost {name} RMSE: {rmse:.2f}')\n",
        "    return rmse\n",
        "\n",
        "rmse_std = run_catboost(X_train_std, X_test_std, name='[A] только признаки')\n",
        "rmse_concat = run_catboost(X_train_concat, X_test_concat, name='[B] признаки + эмбеддинги')\n",
        "rmse_emb = run_catboost(emb_train, emb_test, name='[C] только эмбеддинги')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvOg6jMGHPNQ",
        "outputId": "bb6d5d5e-a8bb-4b56-eda2-e8316c2a989e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-18-1617321670.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
            "/tmp/ipython-input-18-1617321670.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 1.0975\n",
            "Epoch 20, Loss: 0.3672\n",
            "Epoch 40, Loss: 0.2288\n",
            "Epoch 60, Loss: 0.1918\n",
            "Epoch 80, Loss: 0.1697\n",
            "Epoch 100, Loss: 0.1595\n",
            "Epoch 120, Loss: 0.1509\n",
            "Epoch 140, Loss: 0.1431\n",
            "Epoch 160, Loss: 0.1354\n",
            "Epoch 180, Loss: 0.1305\n",
            "Epoch 200, Loss: 0.1228\n",
            "Epoch 220, Loss: 0.1214\n",
            "Epoch 240, Loss: 0.1155\n",
            "Epoch 260, Loss: 0.1138\n",
            "Epoch 280, Loss: 0.1098\n",
            "Epoch 300, Loss: 0.1069\n",
            "Epoch 320, Loss: 0.1044\n",
            "Epoch 340, Loss: 0.1016\n",
            "Epoch 360, Loss: 0.0981\n",
            "Epoch 380, Loss: 0.0972\n",
            "Epoch 400, Loss: 0.0955\n",
            "Epoch 420, Loss: 0.0927\n",
            "Epoch 440, Loss: 0.0916\n",
            "Epoch 460, Loss: 0.0908\n",
            "Epoch 480, Loss: 0.0881\n",
            "Epoch 500, Loss: 0.0856\n",
            "Epoch 520, Loss: 0.0845\n",
            "Epoch 540, Loss: 0.0851\n",
            "Epoch 560, Loss: 0.0837\n",
            "Epoch 580, Loss: 0.0800\n",
            "Epoch 600, Loss: 0.0811\n",
            "Epoch 620, Loss: 0.0787\n",
            "Epoch 640, Loss: 0.0789\n",
            "Epoch 660, Loss: 0.0790\n",
            "Epoch 680, Loss: 0.0769\n",
            "CatBoost [A] только признаки RMSE: 5188808.43\n",
            "CatBoost [B] признаки + эмбеддинги RMSE: 5170425.79\n",
            "CatBoost [C] только эмбеддинги RMSE: 5333307.35\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import SAGEConv, BatchNorm\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "# Обработка пропусков\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем признаки и таргеты\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# === 2. Строим граф по KNN (10 соседей) ===\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Маски\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 3. GNN-модель ===\n",
        "class DeepGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.3):\n",
        "        super(DeepGNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = BatchNorm(hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = BatchNorm(hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, return_embeddings=False):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return x  # Вернуть эмбеддинги до MLP\n",
        "        return self.mlp(x)\n",
        "\n",
        "# === 4. Обучение GNN ===\n",
        "\n",
        "model = DeepGNN(in_channels=X_all.shape[1], hidden_channels=256, out_channels=1, dropout=0.3)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(700):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 5. Извлечение эмбеддингов ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    embeddings = model(data.x, data.edge_index, return_embeddings=True).cpu().numpy()\n",
        "    emb_train = embeddings[:len(df_train)]\n",
        "    emb_test = embeddings[len(df_train):]\n",
        "\n",
        "# === 6. Обучение CatBoost на трех вариантах ===\n",
        "\n",
        "X_train_std = df_train.values\n",
        "X_test_std = df_test.values\n",
        "\n",
        "X_train_concat = np.hstack([X_train_std, emb_train])\n",
        "X_test_concat = np.hstack([X_test_std, emb_test])\n",
        "\n",
        "# Опции CatBoost\n",
        "params = dict(verbose=0, iterations=300, random_seed=42)\n",
        "\n",
        "def run_catboost(X_tr, X_te, name=''):\n",
        "    model = CatBoostRegressor(**params)\n",
        "    model.fit(X_tr, y_train)\n",
        "    preds = model.predict(X_te)\n",
        "    rmse = mean_squared_error(y_test, preds) ** 0.5\n",
        "    print(f'CatBoost {name} RMSE: {rmse:.2f}')\n",
        "    return rmse\n",
        "\n",
        "rmse_std = run_catboost(X_train_std, X_test_std, name='[A] только признаки')\n",
        "rmse_concat = run_catboost(X_train_concat, X_test_concat, name='[B] признаки + эмбеддинги')\n",
        "rmse_emb = run_catboost(emb_train, emb_test, name='[C] только эмбеддинги')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uoz7pGzgHPKj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import SAGEConv, BatchNorm\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "# Обработка пропусков\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем признаки и таргеты\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# === 2. Строим граф по KNN (10 соседей) ===\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Маски\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 3. GNN-модель ===\n",
        "class DeepGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.3):\n",
        "        super(DeepGNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = BatchNorm(hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = BatchNorm(hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, return_embeddings=False):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return x  # Вернуть эмбеддинги до MLP\n",
        "        return self.mlp(x)\n",
        "\n",
        "# === 4. Обучение GNN ===\n",
        "\n",
        "model = DeepGNN(in_channels=X_all.shape[1], hidden_channels=256, out_channels=1, dropout=0.3)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(700):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 5. Извлечение эмбеддингов ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    embeddings = model(data.x, data.edge_index, return_embeddings=True).cpu().numpy()\n",
        "    emb_train = embeddings[:len(df_train)]\n",
        "    emb_test = embeddings[len(df_train):]\n",
        "\n",
        "# === 6. Обучение CatBoost на трех вариантах ===\n",
        "\n",
        "X_train_std = df_train.values\n",
        "X_test_std = df_test.values\n",
        "\n",
        "X_train_concat = np.hstack([X_train_std, emb_train])\n",
        "X_test_concat = np.hstack([X_test_std, emb_test])\n",
        "\n",
        "# Опции CatBoost\n",
        "params = dict(verbose=0, iterations=1000, random_seed=42)\n",
        "\n",
        "def run_catboost(X_tr, X_te, name=''):\n",
        "    model = CatBoostRegressor(**params)\n",
        "    model.fit(X_tr, y_train)\n",
        "    preds = model.predict(X_te)\n",
        "    rmse = mean_squared_error(y_test, preds) ** 0.5\n",
        "    print(f'CatBoost {name} RMSE: {rmse:.2f}')\n",
        "    return rmse\n",
        "\n",
        "rmse_std = run_catboost(X_train_std, X_test_std, name='[A] только признаки')\n",
        "rmse_concat = run_catboost(X_train_concat, X_test_concat, name='[B] признаки + эмбеддинги')\n",
        "rmse_emb = run_catboost(emb_train, emb_test, name='[C] только эмбеддинги')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-k5JlXQZNxU1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnASg77UyIwY"
      },
      "source": [
        "## 500 EPOCHS LR=0.0001 DROPOUT=0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WPGZpgxyHZ_",
        "outputId": "1ac75b7b-8003-4dbf-8a44-fe6793c20210"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3-1461267539.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
            "/tmp/ipython-input-3-1461267539.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 1.0099\n",
            "Epoch 20, Loss: 0.6135\n",
            "Epoch 40, Loss: 0.3343\n",
            "Epoch 60, Loss: 0.2696\n",
            "Epoch 80, Loss: 0.2303\n",
            "Epoch 100, Loss: 0.2159\n",
            "Epoch 120, Loss: 0.2025\n",
            "Epoch 140, Loss: 0.1917\n",
            "Epoch 160, Loss: 0.1768\n",
            "Epoch 180, Loss: 0.1785\n",
            "Epoch 200, Loss: 0.1708\n",
            "Epoch 220, Loss: 0.1685\n",
            "Epoch 240, Loss: 0.1597\n",
            "Epoch 260, Loss: 0.1548\n",
            "Epoch 280, Loss: 0.1498\n",
            "Epoch 300, Loss: 0.1474\n",
            "Epoch 320, Loss: 0.1411\n",
            "Epoch 340, Loss: 0.1402\n",
            "Epoch 360, Loss: 0.1371\n",
            "Epoch 380, Loss: 0.1324\n",
            "Epoch 400, Loss: 0.1333\n",
            "Epoch 420, Loss: 0.1307\n",
            "Epoch 440, Loss: 0.1285\n",
            "Epoch 460, Loss: 0.1263\n",
            "Epoch 480, Loss: 0.1241\n",
            "Epoch 500, Loss: 0.1233\n",
            "Epoch 520, Loss: 0.1208\n",
            "Epoch 540, Loss: 0.1173\n",
            "Epoch 560, Loss: 0.1216\n",
            "Epoch 580, Loss: 0.1156\n",
            "Epoch 600, Loss: 0.1166\n",
            "Epoch 620, Loss: 0.1145\n",
            "Epoch 640, Loss: 0.1140\n",
            "Epoch 660, Loss: 0.1113\n",
            "Epoch 680, Loss: 0.1103\n",
            "True values: [19750000. 10100000. 16900000. 31900000. 31300000. 29000000. 13150000.\n",
            " 37000000.  9771580. 14900000.]\n",
            "Predictions: [15185498. 10829550. 14711090. 29082276. 29207710. 25256788. 13565852.\n",
            " 42528032. 11170426. 13601829.]\n",
            "Test RMSE: 5703578.10\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from torch_geometric.nn import SAGEConv, BatchNorm\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "# Загрузка\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем для построения общего графа\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "\n",
        "# Извлекаем только признаки\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# Строим граф по KNN (10 ближайших соседей)\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# Создаём PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Разбиваем обратно на train/test\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 2. Определение модели ===\n",
        "\n",
        "class DeepGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.3):\n",
        "        super(DeepGNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.mlp(x)\n",
        "        return x\n",
        "\n",
        "model = DeepGNN(in_channels=X_all.shape[1], hidden_channels=128, out_channels=1, dropout=0.4)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# === 3. Обучение модели ===\n",
        "\n",
        "model.train()\n",
        "for epoch in range(700):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 4. Оценка ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze().cpu().numpy()\n",
        "    preds = target_scaler.inverse_transform(preds_scaled.reshape(-1, 1)).flatten()\n",
        "    true = y_train.tolist() + y_test.tolist()\n",
        "\n",
        "    # Выводим первые 10\n",
        "    print('True values:', np.array(true[:10]))\n",
        "    print('Predictions:', preds[:10])\n",
        "\n",
        "    # RMSE по тесту\n",
        "    rmse = mean_squared_error(\n",
        "        y_test,\n",
        "        preds[len(df_train):]\n",
        "    ) ** 0.5\n",
        "    print(f'Test RMSE: {rmse:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLbSNEclytTd"
      },
      "source": [
        "## 600 EPOCHS LR=0.0001 DROPOUT=0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tjZD_6fytKp",
        "outputId": "705271e2-1ef0-4bd7-8093-7d1c43d9c6f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4-769833223.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
            "/tmp/ipython-input-4-769833223.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 0.9841\n",
            "Epoch 20, Loss: 0.3106\n",
            "Epoch 40, Loss: 0.2196\n",
            "Epoch 60, Loss: 0.1810\n",
            "Epoch 80, Loss: 0.1648\n",
            "Epoch 100, Loss: 0.1558\n",
            "Epoch 120, Loss: 0.1460\n",
            "Epoch 140, Loss: 0.1377\n",
            "Epoch 160, Loss: 0.1312\n",
            "Epoch 180, Loss: 0.1264\n",
            "Epoch 200, Loss: 0.1185\n",
            "Epoch 220, Loss: 0.1159\n",
            "Epoch 240, Loss: 0.1114\n",
            "Epoch 260, Loss: 0.1085\n",
            "Epoch 280, Loss: 0.1050\n",
            "Epoch 300, Loss: 0.1036\n",
            "Epoch 320, Loss: 0.1009\n",
            "Epoch 340, Loss: 0.1008\n",
            "Epoch 360, Loss: 0.0958\n",
            "Epoch 380, Loss: 0.0935\n",
            "Epoch 400, Loss: 0.0932\n",
            "Epoch 420, Loss: 0.0906\n",
            "Epoch 440, Loss: 0.0898\n",
            "Epoch 460, Loss: 0.0861\n",
            "Epoch 480, Loss: 0.0860\n",
            "Epoch 500, Loss: 0.0836\n",
            "Epoch 520, Loss: 0.0817\n",
            "Epoch 540, Loss: 0.0812\n",
            "Epoch 560, Loss: 0.0804\n",
            "Epoch 580, Loss: 0.0796\n",
            "Epoch 600, Loss: 0.0783\n",
            "Epoch 620, Loss: 0.0785\n",
            "Epoch 640, Loss: 0.0776\n",
            "Epoch 660, Loss: 0.0765\n",
            "Epoch 680, Loss: 0.0756\n",
            "True values: [19750000. 10100000. 16900000. 31900000. 31300000. 29000000. 13150000.\n",
            " 37000000.  9771580. 14900000.]\n",
            "Predictions: [17863600. 10838048. 14815050. 29986226. 28191754. 29077366. 14033858.\n",
            " 47925840.  9939199. 13360724.]\n",
            "Test RMSE: 5215205.37\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from torch_geometric.nn import SAGEConv, BatchNorm\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "# Загрузка\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем для построения общего графа\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "\n",
        "# Извлекаем только признаки\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# Строим граф по KNN (10 ближайших соседей)\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# Создаём PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Разбиваем обратно на train/test\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 2. Определение модели ===\n",
        "\n",
        "class DeepGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.3):\n",
        "        super(DeepGNN, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels // 2, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.mlp(x)\n",
        "        return x\n",
        "\n",
        "model = DeepGNN(in_channels=X_all.shape[1], hidden_channels=256, out_channels=1, dropout=0.3)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# === 3. Обучение модели ===\n",
        "\n",
        "model.train()\n",
        "for epoch in range(700):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 4. Оценка ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze().cpu().numpy()\n",
        "    preds = target_scaler.inverse_transform(preds_scaled.reshape(-1, 1)).flatten()\n",
        "    true = y_train.tolist() + y_test.tolist()\n",
        "\n",
        "    # Выводим первые 10\n",
        "    print('True values:', np.array(true[:10]))\n",
        "    print('Predictions:', preds[:10])\n",
        "\n",
        "    # RMSE по тесту\n",
        "    rmse = mean_squared_error(\n",
        "        y_test,\n",
        "        preds[len(df_train):]\n",
        "    ) ** 0.5\n",
        "    print(f'Test RMSE: {rmse:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xa91I6nydrE"
      },
      "source": [
        "# GAT + JK 500 epochs LR=0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzd6oc7DvF5K"
      },
      "outputs": [],
      "source": [
        "усилим архитектуру с помощью Graph Attention Networks (GAT) и Jumping Knowledge (JK). Это даст модели возможность:\n",
        "\n",
        "GAT — фокусироваться на важности соседей через attention.\n",
        "\n",
        "Jumping Knowledge — агрегировать представления из разных глубин графа (из всех GNN-слоев), что помогает при градиентных затуханиях и переусложнении."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXJiNdi1vF2X",
        "outputId": "f35af8f8-4adc-492f-a144-7a57407ae9e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-59-842969465.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
            "/tmp/ipython-input-59-842969465.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 1.0740\n",
            "Epoch 20, Loss: 0.2354\n",
            "Epoch 40, Loss: 0.1928\n",
            "Epoch 60, Loss: 0.1738\n",
            "Epoch 80, Loss: 0.1633\n",
            "Epoch 100, Loss: 0.1619\n",
            "Epoch 120, Loss: 0.1564\n",
            "Epoch 140, Loss: 0.1501\n",
            "Epoch 160, Loss: 0.1455\n",
            "Epoch 180, Loss: 0.1446\n",
            "Epoch 200, Loss: 0.1423\n",
            "Epoch 220, Loss: 0.1398\n",
            "Epoch 240, Loss: 0.1369\n",
            "Epoch 260, Loss: 0.1347\n",
            "Epoch 280, Loss: 0.1327\n",
            "Epoch 300, Loss: 0.1311\n",
            "Epoch 320, Loss: 0.1292\n",
            "Epoch 340, Loss: 0.1332\n",
            "Epoch 360, Loss: 0.1281\n",
            "Epoch 380, Loss: 0.1249\n",
            "Epoch 400, Loss: 0.1267\n",
            "Epoch 420, Loss: 0.1229\n",
            "Epoch 440, Loss: 0.1228\n",
            "Epoch 460, Loss: 0.1234\n",
            "Epoch 480, Loss: 0.1219\n",
            "True values: [19750000. 10100000. 16900000. 31900000. 31300000. 29000000. 13150000.\n",
            " 37000000.  9771580. 14900000.]\n",
            "Predictions: [15928250. 10457849. 14608371. 29919222. 29281144. 25930926. 14516802.\n",
            " 36612548. 10647432. 13875816.]\n",
            "Test RMSE: 5966135.04\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from torch_geometric.nn import GATConv, BatchNorm, JumpingKnowledge\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "# Загрузка\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем для построения общего графа\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "\n",
        "# Извлекаем только признаки\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# Строим граф по KNN (10 ближайших соседей)\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# Создаём PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Разбиваем обратно на train/test\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 2. Определение модели ===\n",
        "\n",
        "class GATWithJK(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads=4, dropout=0.3):\n",
        "        super(GATWithJK, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
        "        self.bn1 = BatchNorm(hidden_channels * heads)\n",
        "\n",
        "        self.gat2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout)\n",
        "        self.bn2 = BatchNorm(hidden_channels * heads)\n",
        "\n",
        "        self.gat3 = GATConv(hidden_channels * heads, hidden_channels, heads=1, concat=True, dropout=dropout)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.jk = JumpingKnowledge(mode='cat')  # concatenate all layer outputs\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels * (2 * heads + 1), hidden_channels),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        out1 = self.gat1(x, edge_index)\n",
        "        out1 = self.bn1(out1)\n",
        "        out1 = F.elu(out1)\n",
        "        out1 = F.dropout(out1, p=self.dropout, training=self.training)\n",
        "\n",
        "        out2 = self.gat2(out1, edge_index)\n",
        "        out2 = self.bn2(out2)\n",
        "        out2 = F.elu(out2)\n",
        "        out2 = F.dropout(out2, p=self.dropout, training=self.training)\n",
        "\n",
        "        out3 = self.gat3(out2, edge_index)\n",
        "        out3 = self.bn3(out3)\n",
        "        out3 = F.elu(out3)\n",
        "\n",
        "        x = self.jk([out1, out2, out3])\n",
        "        x = self.mlp(x)\n",
        "        return x\n",
        "model = GATWithJK(\n",
        "    in_channels=X_all.shape[1],  # количество признаков, включая emb_*\n",
        "    hidden_channels=64,\n",
        "    out_channels=1,\n",
        "    heads=4,\n",
        "    dropout=0.4\n",
        ")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# === 3. Обучение модели ===\n",
        "\n",
        "model.train()\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 4. Оценка ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze().cpu().numpy()\n",
        "    preds = target_scaler.inverse_transform(preds_scaled.reshape(-1, 1)).flatten()\n",
        "    true = y_train.tolist() + y_test.tolist()\n",
        "\n",
        "    # Выводим первые 10\n",
        "    print('True values:', np.array(true[:10]))\n",
        "    print('Predictions:', preds[:10])\n",
        "\n",
        "    # RMSE по тесту\n",
        "    rmse = mean_squared_error(\n",
        "        y_test,\n",
        "        preds[len(df_train):]\n",
        "    ) ** 0.5\n",
        "    print(f'Test RMSE: {rmse:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvEpz5dpfQFE",
        "outputId": "57f51da8-a044-444c-9578-15b6347cda60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-63-614215548.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
            "/tmp/ipython-input-63-614215548.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 1.2233\n",
            "Epoch 20, Loss: 0.2535\n",
            "Epoch 40, Loss: 0.1997\n",
            "Epoch 60, Loss: 0.1785\n",
            "Epoch 80, Loss: 0.1688\n",
            "Epoch 100, Loss: 0.1640\n",
            "Epoch 120, Loss: 0.1556\n",
            "Epoch 140, Loss: 0.1533\n",
            "Epoch 160, Loss: 0.1497\n",
            "Epoch 180, Loss: 0.1487\n",
            "Epoch 200, Loss: 0.1477\n",
            "Epoch 220, Loss: 0.1411\n",
            "Epoch 240, Loss: 0.1445\n",
            "Epoch 260, Loss: 0.1397\n",
            "Epoch 280, Loss: 0.1384\n",
            "Epoch 300, Loss: 0.1385\n",
            "Epoch 320, Loss: 0.1345\n",
            "Epoch 340, Loss: 0.1354\n",
            "Epoch 360, Loss: 0.1343\n",
            "Epoch 380, Loss: 0.1300\n",
            "Epoch 400, Loss: 0.1308\n",
            "Epoch 420, Loss: 0.1296\n",
            "Epoch 440, Loss: 0.1268\n",
            "Epoch 460, Loss: 0.1265\n",
            "Epoch 480, Loss: 0.1275\n",
            "True values: [19750000. 10100000. 16900000. 31900000. 31300000. 29000000. 13150000.\n",
            " 37000000.  9771580. 14900000.]\n",
            "Predictions: [16060455. 11874409. 14304381. 28776264. 28888258. 26710058. 13920800.\n",
            " 44423140. 10306080. 13847341.]\n",
            "Test RMSE: 5884138.44\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from torch_geometric.nn import GATConv, BatchNorm, JumpingKnowledge\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "# Загрузка\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем для построения общего графа\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "\n",
        "# Извлекаем только признаки\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# Строим граф по KNN (10 ближайших соседей)\n",
        "A = kneighbors_graph(X_all, n_neighbors=5, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# Создаём PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Разбиваем обратно на train/test\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 2. Определение модели ===\n",
        "\n",
        "class GATWithJK(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads=3, dropout=0.3):\n",
        "        super(GATWithJK, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
        "        self.bn1 = BatchNorm(hidden_channels * heads)\n",
        "\n",
        "        self.gat2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout)\n",
        "        self.bn2 = BatchNorm(hidden_channels * heads)\n",
        "\n",
        "        self.gat3 = GATConv(hidden_channels * heads, hidden_channels, heads=1, concat=True, dropout=dropout)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.jk = JumpingKnowledge(mode='cat')  # concatenate all layer outputs\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels * (2 * heads + 1), hidden_channels),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        out1 = self.gat1(x, edge_index)\n",
        "        out1 = self.bn1(out1)\n",
        "        out1 = F.elu(out1)\n",
        "        out1 = F.dropout(out1, p=self.dropout, training=self.training)\n",
        "\n",
        "        out2 = self.gat2(out1, edge_index)\n",
        "        out2 = self.bn2(out2)\n",
        "        out2 = F.elu(out2)\n",
        "        out2 = F.dropout(out2, p=self.dropout, training=self.training)\n",
        "\n",
        "        out3 = self.gat3(out2, edge_index)\n",
        "        out3 = self.bn3(out3)\n",
        "        out3 = F.elu(out3)\n",
        "\n",
        "        x = self.jk([out1, out2, out3])\n",
        "        x = self.mlp(x)\n",
        "        return x\n",
        "model = GATWithJK(\n",
        "    in_channels=X_all.shape[1],  # количество признаков, включая emb_*\n",
        "    hidden_channels=64,\n",
        "    out_channels=1,\n",
        "    heads=4,\n",
        "    dropout=0.4\n",
        ")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# === 3. Обучение модели ===\n",
        "\n",
        "model.train()\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 4. Оценка ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze().cpu().numpy()\n",
        "    preds = target_scaler.inverse_transform(preds_scaled.reshape(-1, 1)).flatten()\n",
        "    true = y_train.tolist() + y_test.tolist()\n",
        "\n",
        "    # Выводим первые 10\n",
        "    print('True values:', np.array(true[:10]))\n",
        "    print('Predictions:', preds[:10])\n",
        "\n",
        "    # RMSE по тесту\n",
        "    rmse = mean_squared_error(\n",
        "        y_test,\n",
        "        preds[len(df_train):]\n",
        "    ) ** 0.5\n",
        "    print(f'Test RMSE: {rmse:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qbJNwBJdu1l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_bVbWbA50au",
        "outputId": "ed3b3d7b-a82d-46e4-b6f9-86baf150ae65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-60-1661658405.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
            "/tmp/ipython-input-60-1661658405.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 1.1089\n",
            "Epoch 20, Loss: 0.5017\n",
            "Epoch 40, Loss: 0.3643\n",
            "Epoch 60, Loss: 0.3114\n",
            "Epoch 80, Loss: 0.2810\n",
            "Epoch 100, Loss: 0.2685\n",
            "Epoch 120, Loss: 0.2545\n",
            "Epoch 140, Loss: 0.2429\n",
            "Epoch 160, Loss: 0.2271\n",
            "Epoch 180, Loss: 0.2238\n",
            "Epoch 200, Loss: 0.2122\n",
            "Epoch 220, Loss: 0.2118\n",
            "Epoch 240, Loss: 0.2035\n",
            "Epoch 260, Loss: 0.2004\n",
            "Epoch 280, Loss: 0.1981\n",
            "Epoch 300, Loss: 0.1925\n",
            "Epoch 320, Loss: 0.1882\n",
            "Epoch 340, Loss: 0.1873\n",
            "Epoch 360, Loss: 0.1844\n",
            "Epoch 380, Loss: 0.1839\n",
            "Epoch 400, Loss: 0.1833\n",
            "Epoch 420, Loss: 0.1796\n",
            "Epoch 440, Loss: 0.1768\n",
            "Epoch 460, Loss: 0.1781\n",
            "Epoch 480, Loss: 0.1765\n",
            "True values: [19750000. 10100000. 16900000. 31900000. 31300000. 29000000. 13150000.\n",
            " 37000000.  9771580. 14900000.]\n",
            "Predictions: [16552404. 11033623. 15374494. 27908692. 29027126. 24963698. 17212064.\n",
            " 34643104. 11724708. 13720763.]\n",
            "Test RMSE: 6741784.12\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from torch_geometric.nn import GATConv, BatchNorm, JumpingKnowledge\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "# Загрузка\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем для построения общего графа\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "\n",
        "# Извлекаем только признаки\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# Строим граф по KNN (10 ближайших соседей)\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# Создаём PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Разбиваем обратно на train/test\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 2. Определение модели ===\n",
        "\n",
        "class GATWithJK(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads=4, dropout=0.3):\n",
        "        super(GATWithJK, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
        "        self.bn1 = BatchNorm(hidden_channels * heads)\n",
        "\n",
        "        self.gat2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout)\n",
        "        self.bn2 = BatchNorm(hidden_channels * heads)\n",
        "\n",
        "        self.gat3 = GATConv(hidden_channels * heads, hidden_channels, heads=1, concat=True, dropout=dropout)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.jk = JumpingKnowledge(mode='cat')  # concatenate all layer outputs\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels * (2 * heads + 1), hidden_channels),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        out1 = self.gat1(x, edge_index)\n",
        "        out1 = self.bn1(out1)\n",
        "        out1 = F.elu(out1)\n",
        "        out1 = F.dropout(out1, p=self.dropout, training=self.training)\n",
        "\n",
        "        out2 = self.gat2(out1, edge_index)\n",
        "        out2 = self.bn2(out2)\n",
        "        out2 = F.elu(out2)\n",
        "        out2 = F.dropout(out2, p=self.dropout, training=self.training)\n",
        "\n",
        "        out3 = self.gat3(out2, edge_index)\n",
        "        out3 = self.bn3(out3)\n",
        "        out3 = F.elu(out3)\n",
        "\n",
        "        x = self.jk([out1, out2, out3])\n",
        "        x = self.mlp(x)\n",
        "        return x\n",
        "model = GATWithJK(\n",
        "    in_channels=X_all.shape[1],  # количество признаков, включая emb_*\n",
        "    hidden_channels=64,\n",
        "    out_channels=1,\n",
        "    heads=4,\n",
        "    dropout=0.4\n",
        ")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# === 3. Обучение модели ===\n",
        "\n",
        "model.train()\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 4. Оценка ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze().cpu().numpy()\n",
        "    preds = target_scaler.inverse_transform(preds_scaled.reshape(-1, 1)).flatten()\n",
        "    true = y_train.tolist() + y_test.tolist()\n",
        "\n",
        "    # Выводим первые 10\n",
        "    print('True values:', np.array(true[:10]))\n",
        "    print('Predictions:', preds[:10])\n",
        "\n",
        "    # RMSE по тесту\n",
        "    rmse = mean_squared_error(\n",
        "        y_test,\n",
        "        preds[len(df_train):]\n",
        "    ) ** 0.5\n",
        "    print(f'Test RMSE: {rmse:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vEOe-K750YK",
        "outputId": "009df98f-92ea-479c-f26e-1e3dcbde8dba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-61-3781163976.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
            "/tmp/ipython-input-61-3781163976.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: overflow encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 1.0559\n",
            "Epoch 20, Loss: 0.2757\n",
            "Epoch 40, Loss: 0.2151\n",
            "Epoch 60, Loss: 0.1900\n",
            "Epoch 80, Loss: 0.1806\n",
            "Epoch 100, Loss: 0.1684\n",
            "Epoch 120, Loss: 0.1614\n",
            "Epoch 140, Loss: 0.1572\n",
            "Epoch 160, Loss: 0.1531\n",
            "Epoch 180, Loss: 0.1486\n",
            "Epoch 200, Loss: 0.1519\n",
            "Epoch 220, Loss: 0.1453\n",
            "Epoch 240, Loss: 0.1423\n",
            "Epoch 260, Loss: 0.1407\n",
            "Epoch 280, Loss: 0.1391\n",
            "Epoch 300, Loss: 0.1373\n",
            "Epoch 320, Loss: 0.1365\n",
            "Epoch 340, Loss: 0.1369\n",
            "Epoch 360, Loss: 0.1314\n",
            "Epoch 380, Loss: 0.1317\n",
            "Epoch 400, Loss: 0.1323\n",
            "Epoch 420, Loss: 0.1269\n",
            "Epoch 440, Loss: 0.1290\n",
            "Epoch 460, Loss: 0.1268\n",
            "Epoch 480, Loss: 0.1314\n",
            "True values: [19750000. 10100000. 16900000. 31900000. 31300000. 29000000. 13150000.\n",
            " 37000000.  9771580. 14900000.]\n",
            "Predictions: [15943336. 10905781. 14320043. 29991792. 29472586. 25686128. 14095543.\n",
            " 36890552.  9952932. 14128744.]\n",
            "Test RMSE: 6026126.23\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from torch_geometric.nn import GATConv, BatchNorm, JumpingKnowledge\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "# Загрузка\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем для построения общего графа\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "\n",
        "# Извлекаем только признаки\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# Строим граф по KNN (10 ближайших соседей)\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# Создаём PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Разбиваем обратно на train/test\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 2. Определение модели ===\n",
        "\n",
        "class GATWithJK(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads=4, dropout=0.3):\n",
        "        super(GATWithJK, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
        "        self.bn1 = BatchNorm(hidden_channels * heads)\n",
        "\n",
        "        self.gat2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout)\n",
        "        self.bn2 = BatchNorm(hidden_channels * heads)\n",
        "\n",
        "        self.gat3 = GATConv(hidden_channels * heads, hidden_channels, heads=1, concat=True, dropout=dropout)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.jk = JumpingKnowledge(mode='cat')  # concatenate all layer outputs\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels * (2 * heads + 1), hidden_channels),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        out1 = self.gat1(x, edge_index)\n",
        "        out1 = self.bn1(out1)\n",
        "        out1 = F.elu(out1)\n",
        "        out1 = F.dropout(out1, p=self.dropout, training=self.training)\n",
        "\n",
        "        out2 = self.gat2(out1, edge_index)\n",
        "        out2 = self.bn2(out2)\n",
        "        out2 = F.elu(out2)\n",
        "        out2 = F.dropout(out2, p=self.dropout, training=self.training)\n",
        "\n",
        "        out3 = self.gat3(out2, edge_index)\n",
        "        out3 = self.bn3(out3)\n",
        "        out3 = F.elu(out3)\n",
        "\n",
        "        x = self.jk([out1, out2, out3])\n",
        "        x = self.mlp(x)\n",
        "        return x\n",
        "model = GATWithJK(\n",
        "    in_channels=X_all.shape[1],  # количество признаков, включая emb_*\n",
        "    hidden_channels=64,\n",
        "    out_channels=1,\n",
        "    heads=4,\n",
        "    dropout=0.4\n",
        ")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# === 3. Обучение модели ===\n",
        "\n",
        "model.train()\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 4. Оценка ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze().cpu().numpy()\n",
        "    preds = target_scaler.inverse_transform(preds_scaled.reshape(-1, 1)).flatten()\n",
        "    true = y_train.tolist() + y_test.tolist()\n",
        "\n",
        "    # Выводим первые 10\n",
        "    print('True values:', np.array(true[:10]))\n",
        "    print('Predictions:', preds[:10])\n",
        "\n",
        "    # RMSE по тесту\n",
        "    rmse = mean_squared_error(\n",
        "        y_test,\n",
        "        preds[len(df_train):]\n",
        "    ) ** 0.5\n",
        "    print(f'Test RMSE: {rmse:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "s7pi8cFu50Vm",
        "outputId": "a86b508c-2bb2-4c7b-bd67-9fa6e36f5881"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-3799676896.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkneighbors_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhome\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_home_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_home_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_mps_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_xpu_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0misinstance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_torch_instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_debug_enabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/isinstance.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWITH_PT20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalStateGuard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ordered_set\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_traceable_wrapper_subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m from torch.utils._sympy.functions import (\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mApplication\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mCeilToInt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_sympy/functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msympify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpquo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mpexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_gcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/polys/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from torch_geometric.nn import GATConv, BatchNorm, JumpingKnowledge\n",
        "\n",
        "# === 1. Загрузка и подготовка данных ===\n",
        "\n",
        "# Загрузка\n",
        "df_train = pd.read_pickle('X_train_mosc_wembs.pickle')\n",
        "df_test = pd.read_pickle('X_test_mosc_wembs.pickle')\n",
        "y_train = pd.read_pickle('y_train_msk_merged_2.pkl')\n",
        "y_test = pd.read_pickle('y_test_msk_merged_2.pkl')\n",
        "\n",
        "for column in df_train.columns:\n",
        "    df_train[column].fillna(df_train[column].mean(), inplace=True)\n",
        "    df_test[column].fillna(df_test[column].mean(), inplace=True)\n",
        "\n",
        "# Масштабируем таргеты\n",
        "target_scaler = StandardScaler()\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Объединяем для построения общего графа\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
        "y_all = np.vstack([y_train_scaled, y_test_scaled])\n",
        "\n",
        "# Извлекаем только признаки\n",
        "X_all = df_all.values.astype(np.float32)\n",
        "\n",
        "# Строим граф по KNN (10 ближайших соседей)\n",
        "A = kneighbors_graph(X_all, n_neighbors=10, mode='connectivity', include_self=False)\n",
        "edge_index = torch.tensor(np.array(A.nonzero()), dtype=torch.long)\n",
        "\n",
        "# Создаём PyG Data\n",
        "data = Data(\n",
        "    x=torch.tensor(X_all, dtype=torch.float),\n",
        "    edge_index=edge_index,\n",
        "    y=torch.tensor(y_all, dtype=torch.float)\n",
        ")\n",
        "\n",
        "# Разбиваем обратно на train/test\n",
        "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "train_mask[:len(df_train)] = True\n",
        "test_mask[len(df_train):] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# === 2. Определение модели ===\n",
        "\n",
        "class GATWithJK(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads=7, dropout=0.3):\n",
        "        super(GATWithJK, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
        "        self.bn1 = BatchNorm(hidden_channels * heads)\n",
        "\n",
        "        self.gat2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout)\n",
        "        self.bn2 = BatchNorm(hidden_channels * heads)\n",
        "\n",
        "        self.gat3 = GATConv(hidden_channels * heads, hidden_channels, heads=1, concat=True, dropout=dropout)\n",
        "        self.bn3 = BatchNorm(hidden_channels)\n",
        "\n",
        "        self.jk = JumpingKnowledge(mode='cat')  # concatenate all layer outputs\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(hidden_channels * (2 * heads + 1), hidden_channels),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(hidden_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        out1 = self.gat1(x, edge_index)\n",
        "        out1 = self.bn1(out1)\n",
        "        out1 = F.elu(out1)\n",
        "        out1 = F.dropout(out1, p=self.dropout, training=self.training)\n",
        "\n",
        "        out2 = self.gat2(out1, edge_index)\n",
        "        out2 = self.bn2(out2)\n",
        "        out2 = F.elu(out2)\n",
        "        out2 = F.dropout(out2, p=self.dropout, training=self.training)\n",
        "\n",
        "        out3 = self.gat3(out2, edge_index)\n",
        "        out3 = self.bn3(out3)\n",
        "        out3 = F.elu(out3)\n",
        "\n",
        "        x = self.jk([out1, out2, out3])\n",
        "        x = self.mlp(x)\n",
        "        return x\n",
        "model = GATWithJK(\n",
        "    in_channels=X_all.shape[1],  # количество признаков, включая emb_*\n",
        "    hidden_channels=64,\n",
        "    out_channels=1,\n",
        "    heads=4,\n",
        "    dropout=0.4\n",
        ")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# === 3. Обучение модели ===\n",
        "\n",
        "model.train()\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index).squeeze()\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask].squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# === 4. Оценка ===\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds_scaled = model(data.x, data.edge_index).squeeze().cpu().numpy()\n",
        "    preds = target_scaler.inverse_transform(preds_scaled.reshape(-1, 1)).flatten()\n",
        "    true = y_train.tolist() + y_test.tolist()\n",
        "\n",
        "    # Выводим первые 10\n",
        "    print('True values:', np.array(true[:10]))\n",
        "    print('Predictions:', preds[:10])\n",
        "\n",
        "    # RMSE по тесту\n",
        "    rmse = mean_squared_error(\n",
        "        y_test,\n",
        "        preds[len(df_train):]\n",
        "    ) ** 0.5\n",
        "    print(f'Test RMSE: {rmse:.2f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}